{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52e9b0ad-4e19-4e47-8e19-884f44e282b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e24dbc1-0634-4e64-9f54-5700f7f2212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_to_nifti1(array, original_img, destination_path, output_name):\n",
    "    # Transform the array to a nifti image which requires the affine of the original image.\n",
    "    processed_img = nib.Nifti1Image(array, original_img.affine)\n",
    "    nib.save(processed_img, os.path.join(destination_path, output_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3873a8a9-ed27-4ed2-a07c-e1cf514501e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stroke_closing(img):\n",
    "    # used to close stroke prediction image\n",
    "    new_img = np.zeros_like(img)\n",
    "    new_img = scipy.ndimage.binary_closing(img, structure=np.ones((2,2,2)))\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "809debb0-5456-4a97-ba1a-1c0d059b7689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SkullStripped_Mask(model, SWI_img, TOF_img):\n",
    "    # To inference brain mask from MaskNet model\n",
    "    # model specifies which pre-trained DL model is used to inference\n",
    "    \n",
    "    # Down sampling\n",
    "    swi = SWI_img[0::4,0::4,0::4,np.newaxis] # Down sample for MaskNet, dim should be [48, 56, 48, 1]\n",
    "\n",
    "    tof = TOF_img[0::4,0::4,0::4, np.newaxis] # Down sample for MaskNet, dim should be [48, 56, 48, 1]\n",
    "    x = np.expand_dims(np.concatenate((swi,tof),axis=3), axis=0)\n",
    "\n",
    "    # Standardize x before input into the neural network.\n",
    "    dim_1, dim_2, dim_3, dim_4, dim_5 = x.shape\n",
    "    robust_scaler = preprocessing.RobustScaler()\n",
    "    x_rescaled = standard_scaler.fit_transform(x.reshape(dim_2,-1)).reshape(dim_1,dim_2,dim_3,dim_4,dim_5)\n",
    "    \n",
    "    # inference\n",
    "    y_pred = model.predict(x_rescaled, verbose=0)\n",
    "    y_pred = (np.squeeze(y_pred)>0.5)*1.0\n",
    "\n",
    "    \n",
    "    # the following is post processing of predicted mask by \n",
    "    # 1) selecting the major non-zero voxel\n",
    "    # 2) closing\n",
    "    # 3) binary fill holes\n",
    "    # 4) upsampling to high resolution space by (4,4,4)\n",
    "    \n",
    "    mask_label, num_features = scipy.ndimage.label(y_pred)\n",
    "    dilate_mask = (mask_label == scipy.stats.mode(mask_label[mask_label>0].flatten(), keepdims=True)[0][0])*1\n",
    "    dilate_mask = Stroke_closing(dilate_mask)\n",
    "    dilate_mask = scipy.ndimage.binary_fill_holes(dilate_mask)\n",
    "    upsampling_mask = np.repeat(np.repeat(np.repeat(dilate_mask, 4, axis=0), 4, axis=1), 4, axis=2)\n",
    "\n",
    "    return upsampling_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d57f0af9-1a9b-40ef-9289-6c54013c352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_skullstripping(model, SWI_folder_path, TOF_folder_path, mask_destination_path, swi_img_destination_path, tof_img_destination_path):\n",
    "    swi_files = os.listdir(SWI_folder_path)\n",
    "    tof_files = os.listdir(TOF_folder_path)\n",
    "\n",
    "    # Select files to process.\n",
    "    swi_nifti_files = [file for file in swi_files if file.endswith('.nii.gz')]\n",
    "    tof_nifti_files = [file for file in tof_files if file.endswith('.nii.gz')]\n",
    "\n",
    "    for swi_file, tof_file in zip(swi_nifti_files, tof_nifti_files):\n",
    "        swi_file_path = os.path.join(SWI_folder_path, swi_file)\n",
    "        tof_file_path = os.path.join(TOF_folder_path, tof_file)\n",
    "        swi_nii_img = nib.load(swi_file_path)\n",
    "        swi_nii_data = swi_nii_img.get_fdata()\n",
    "        tof_nii_img = nib.load(tof_file_path)\n",
    "        tof_nii_data = tof_nii_img.get_fdata()\n",
    "\n",
    "        mask_name = os.path.splitext(os.path.splitext(swi_file)[0])[0] + \"_\" + \"Mask\" + \".nii.gz\"\n",
    "        new_swi_img_name = os.path.splitext(os.path.splitext(swi_file)[0])[0] + \"_\" + \"SkullStripped\" + \".nii.gz\"\n",
    "        new_tof_img_name = os.path.splitext(os.path.splitext(tof_file)[0])[0] + \"_\" + \"SkullStripped\" + \".nii.gz\"\n",
    "\n",
    "        mask_data_bool = get_SkullStripped_Mask(model, swi_nii_data, tof_nii_data)\n",
    "        mask_data = mask_data_bool.astype(\"float64\")\n",
    "        save_array_to_nifti1(mask_data, swi_nii_img, mask_destination_path, mask_name)\n",
    "        \n",
    "        skullstripped_swi_data = mask_data * swi_nii_data\n",
    "        skullstripped_tof_data = mask_data * tof_nii_data\n",
    "\n",
    "        save_array_to_nifti1(skullstripped_swi_data, tof_nii_img, swi_img_destination_path, new_swi_img_name)\n",
    "        save_array_to_nifti1(skullstripped_tof_data, swi_nii_img, tof_img_destination_path, new_tof_img_name)\n",
    "        \n",
    "        print(f\"Processed SWI image {swi_file} and TOF image {tof_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55a7c204-01a7-4a9e-b45d-00f5c419c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "MaskNet_name =  os.path.join(\"D:\\ADS_Algorithm\\ADSv1.3\\data\\Trained_Nets\", 'BrainMaskNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5943b471-6868-40c3-85a9-c4b3d09b4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "MaskNet = load_model(MaskNet_name, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a24e714-b470-4521-b9bf-de434e181eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed SWI image 2018-104_01-10087-D0MR_12_SWI_Images_swi3d1r.nii.gz and TOF image 2018-104_01-10087-D0MR_8_TOF_3D_NEW_wo_ARTEFACTS_fl3d1r_t50.nii.gz\n",
      "Processed SWI image 2018-104_01-10113-D0MR_9_Ax_T2_GRE_.nii.gz and TOF image 2018-104_01-10113-D0MR_6_3D_TOF_LARGE_.nii.gz\n",
      "Processed SWI image 2018-104_01-10114-D0MR_7_Ax_3D_SWAN+CARTO_.nii.gz and TOF image 2018-104_01-10114-D0MR_6_3D_TOF_LARGE_.nii.gz\n",
      "Processed SWI image 2018-104_01-10116-D0MR_7_AXIAL_T2_EG_fl2d1.nii.gz and TOF image 2018-104_01-10116-D0MR_8_TOF_3D_WILLIS_FIN_fl3d1r_t70.nii.gz\n",
      "Processed SWI image 2018-104_01-10117-D0MR_7_Ax_T2_GRE_.nii.gz and TOF image 2018-104_01-10117-D0MR_6_3D_TOF_LARGE_.nii.gz\n",
      "Processed SWI image 2018-104_01-10118-D0MR_12_SWI_Images_swi3d1r.nii.gz and TOF image 2018-104_01-10118-D0MR_8_TOF_3D_RAPIDE_fl3d1r_t40.nii.gz\n"
     ]
    }
   ],
   "source": [
    "apply_skullstripping(MaskNet, \"D:\\\\pythonscripts_ETIS\\\\Test_SWI\", \"D:\\\\pythonscripts_ETIS\\\\Test_TOF\", \"D:\\\\pythonscripts_ETIS\\\\Test_Mask\", \"D:\\\\pythonscripts_ETIS\\\\SkullStripped_SWI\", \"D:\\\\pythonscripts_ETIS\\\\SkullStripped_TOF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b7f2144-33bd-480c-9eb4-0a2e67b2fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_nii_img = nib.load(\"D:\\\\pythonscripts_ETIS\\\\Test_SWI\\\\2018-104_01-10087-D0MR_12_SWI_Images_swi3d1r.nii.gz\")\n",
    "swi_nii_data = swi_nii_img.get_fdata()\n",
    "tof_nii_img = nib.load(\"D:\\\\pythonscripts_ETIS\\\\Test_TOF\\\\2018-104_01-10087-D0MR_8_TOF_3D_NEW_wo_ARTEFACTS_fl3d1r_t50.nii.gz\")\n",
    "tof_nii_data = tof_nii_img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc6b16d4-c3b7-40e2-8549-9d4a79a63fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_nii_img_norm = nib.load(\"D:\\\\pythonscripts_ETIS\\\\Test_SWI_norm\\\\2018-104_01-10087-D0MR_12_SWI_Images_swi3d1r_Normalized.nii.gz\")\n",
    "swi_nii_data_norm = swi_nii_img_norm.get_fdata()\n",
    "tof_nii_img_norm = nib.load(\"D:\\\\pythonscripts_ETIS\\\\Test_TOF_Norm\\\\2018-104_01-10087-D0MR_8_TOF_3D_NEW_wo_ARTEFACTS_fl3d1r_t50_Normalized.nii.gz\")\n",
    "tof_nii_data_norm = tof_nii_img_norm.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d946e4e-2f6e-4224-9d0a-c5f7493ff71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_data = get_SkullStripped_Mask(MaskNet, swi_nii_data_norm, tof_nii_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cacf07ff-2fd5-4153-869c-d054847619a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "skullstripped_swi_data = mask_data * swi_nii_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d44fa15-dda5-4c05-af09-908169237b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array_to_nifti1(mask_data.astype(\"float64\"), swi_nii_img, \"D:\\\\pythonscripts_ETIS\", \"test_mask.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e0ed4c5-7ecb-43c0-ab38-79e688ba7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array_to_nifti1(skullstripped_swi_data, swi_nii_img, \"D:\\\\pythonscripts_ETIS\", \"test_swi_skullstripped.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a62842a1-a6c0-458e-8563-de4599118213",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi = swi_nii_data[0::4,0::4,0::4,np.newaxis] # Down sample for MaskNet, dim should be [48, 56, 48, 1]\n",
    "tof = tof_nii_data[0::4,0::4,0::4, np.newaxis] # Down sample for MaskNet, dim should be [48, 56, 48, 1]\n",
    "x = np.expand_dims(np.concatenate((swi,tof),axis=3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca1bd5e3-eeef-46a9-9d0b-caa26a6dc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim, y_dim, z_dim = swi_nii_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b46e1daf-c5d6-4a73-be62-3853327dcce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 56, 48, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b6f9fa0-7b15-492b-bcec-fc10fa616fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 5376)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(48,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19d270e0-12be-459e-b7ef-728361ba79b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(x,x.reshape(48,-1).reshape(1,48,56,48,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1eb5445f-e2f5-4eb6-a2ab-6c92c1f09747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 43008)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swi_nii_data.reshape(x_dim,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c541ee9-f9fc-48ad-b06a-8bc9441b5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = preprocessing.StandardScaler()\n",
    "x_scaled = standard_scaler.fit_transform(x.reshape(48,-1)).reshape(1,48,56,48,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06a05018-2ce1-4be5-a94f-dea130faba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 56, 48, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c00886-7e0d-43d6-a7ce-93277b0e188b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
